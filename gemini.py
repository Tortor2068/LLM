# -*- coding: utf-8 -*-
"""Gemini

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mfh1s8xWJ4a6SPFPGEqyumIC08_Tn0kW

### Importing all packages and software being used
"""
import google.generativeai as genai
from PIL import Image as PILImage
import cv2
import os
import json
import xml.etree.ElementTree as ET

# Remove Google Colab specific imports and functionality
# from google.colab import userdata
# from IPython.display import Image, display
# from google.colab import drive

# drive.mount('/content/drive')  # Remove this line

# Replace with your actual Gemini API key
# You'll need to set your API key manually:
genai.configure(api_key="AIzaSyA7hx_Cv99k5aSOyvI1IJMjLCEl74E_0v0")

# for m in genai.list_models():
#     print(f"Name: {m.name}, Methods: {m.supported_generation_methods}")

# # Create a Gemini model instance
model = genai.GenerativeModel('gemini-1.5-pro')

"""### Image and Radio directories:

The radio directory (script_file_path) currently acceces a google doc describing the radio chatter that would be present in the test image. However this can easily be rerouted to a google doc that whisper would paste its output into, and the image directory (image_file_path), could instead reference an image file that automatically updates with any new information regarding flight patterns.
"""

def parse_xml_file(file_path):
    """Parse XML file and extract relevant information"""
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
        
        # Extract text content from XML
        xml_content = ""
        
        # For METAR data, extract weather information
        if 'metar' in file_path.lower():
            for metar in root.findall('.//METAR'):
                station = metar.find('station_id')
                time = metar.find('observation_time')
                wind = metar.find('wind_speed_kt')
                visibility = metar.find('visibility_statute_mi')
                conditions = metar.findall('.//sky_condition')
                
                xml_content += f"Station: {station.text if station is not None else 'N/A'}\n"
                xml_content += f"Time: {time.text if time is not None else 'N/A'}\n"
                xml_content += f"Wind: {wind.text if wind is not None else 'N/A'} knots\n"
                xml_content += f"Visibility: {visibility.text if visibility is not None else 'N/A'} miles\n"
                
                for condition in conditions:
                    coverage = condition.get('coverage', 'N/A')
                    height = condition.get('cloud_base_ft_agl', 'N/A')
                    xml_content += f"Sky: {coverage} at {height} feet\n"
                xml_content += "\n"
        
        return xml_content
    except Exception as e:
        print(f"Error parsing XML file: {e}")
        return ""

def save_to_srt(content, filename="Gemini_Analysis.srt"):
    """Save content to SRT file format"""
    try:
        # Split content into sentences for better subtitle formatting
        sentences = content.split('. ')
        
        with open(filename, 'w', encoding='utf-8') as file:
            subtitle_number = 1
            start_time = 0
            
            for sentence in sentences:
                if sentence.strip():  # Skip empty sentences
                    # Format time (simple format: HH:MM:SS,mmm)
                    start_seconds = start_time
                    end_seconds = start_time + 5  # 5 seconds per subtitle
                    
                    start_time_str = f"{start_seconds//3600:02d}:{(start_seconds%3600)//60:02d}:{start_seconds%60:02d},{start_seconds%1*1000:03.0f}"
                    end_time_str = f"{end_seconds//3600:02d}:{(end_seconds%3600)//60:02d}:{end_seconds%60:02d},{end_seconds%1*1000:03.0f}"
                    
                    # Write SRT format
                    file.write(f"{subtitle_number}\n")
                    file.write(f"{start_time_str} --> {end_time_str}\n")
                    file.write(f"{sentence.strip()}\n\n")
                    
                    subtitle_number += 1
                    start_time += 5
        
        print(f"Analysis saved to {filename}")
        return filename
    except Exception as e:
        print(f"Error saving to SRT file: {e}")
        return None

def read_file_content(file_path):
    """Read content from various file types"""
    try:
        if os.path.isdir(file_path):
            print(f"Error: '{file_path}' is a directory. Please provide the path to a file.")
            return ""
        elif file_path.endswith('.xml'):
            # Parse XML file
            content = parse_xml_file(file_path)
            print(f"XML file parsed and loaded from: {file_path}")
            return content
        else:
            # Read regular text file
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
                print(f"File loaded from: {file_path}")
                return content
    except FileNotFoundError:
        print(f"File not found: {file_path}")
        return ""
    except Exception as e:
        print(f"An error occurred while trying to read {file_path}: {e}")
        return ""

# Read both SRT and XML files
srt_file_path = 'Transcribed.srt'
xml_file_path = '.metars.xml'

# Read transcript data
transcript_content = read_file_content(srt_file_path)

# Read weather data
weather_content = read_file_content(xml_file_path)

# Combine both data sources
script_content = f"""
TRANSCRIPT DATA:
{transcript_content}

WEATHER DATA:
{weather_content}
"""

# Specify the path to your image file
image_file_path = 'Half Moon Bay.png'  # Updated to use local file path

# Attempt to open and display the image (optional, for verification)
try:
    # Use PIL to open and show the image instead of IPython.display
    img = PILImage.open(image_file_path)
    img.show()  # This will open the image in the default image viewer
    print(f"Image found and displayed from: {image_file_path}")
except FileNotFoundError:
    print(f"Error: The image file '{image_file_path}' was not found.")
except Exception as e:
    print(f"An error occurred while trying to display the image: {e}")


# Load the image using PIL (Pillow) for the API
try:
    # Use PIL.Image.open to load the image data
    img = PILImage.open(image_file_path)
    image_data = img # Use the loaded PIL Image object
except FileNotFoundError:
    print(f"Error: The image file '{image_file_path}' was not found when trying to load for the API.")
    image_data = None
except Exception as e:
    print(f"An error occurred while trying to load the image for the API: {e}")
    image_data = None

"""### Entering the Prompt into Gemini

A string is used as prompt text, and is put into the function alongside the script and image variables.
"""

# Define an interactive text input for the prompt
user_prompt_text = "Analyze both the radio transcript and flight map to assess overall flight safety on a scale of 1-10. What precautions should be taken if any? Use the assesment examples provided to help you format your response." 


# Send the content to the model
if script_content and image_data: # Only send if script was read and image loaded successfully
    content_parts = (f"{script_content} {user_prompt_text}, assesment_example1, assesment_example2", image_data,)
    response = model.generate_content(content_parts)
    print(response.text)
    
    # Save response to SRT file
    save_to_srt(response.text)

elif script_content:
    content_parts = (f"{user_prompt_text} {script_content}")
    response = model.generate_content(content_parts)
    print(response.text)
    
    # Save response to SRT file
    save_to_srt(response.text)
    
elif image_data:
    content_parts = (f"{user_prompt_text}", image_data)
    response = model.generate_content(content_parts)
    print(response.text)
    
    # Save response to SRT file
    save_to_srt(response.text)
    
else:
    print("Neither script nor image could be loaded.")


"""### Key Ideas

Google gemini is a very powerful LLM itself, meaning that it is able to analysis many sources of information (text prompt, images, and radio transcripts). The LLM is also able to determine which aircraft is designated what callsign, simply using the context clues given in the radio transcipt and matching that with what is presented in the airport map

Using these sources of information, its able to not only determine any hazards that are present, but include steps to help de-escalite the situation.
""" 